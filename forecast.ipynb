{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "df = pd.read_csv('enriched_account_information.csv')\n",
    "\n",
    "\n",
    "date_columns = ['open_date', 'card_activation_date', 'date_in_collection']\n",
    "for col in date_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "\n",
    "\n",
    "quarter_cols = [col for col in df.columns if any(q in col for q in ['2023Q', '2024Q', '2025Q'])]\n",
    "spending_cols = [col for col in quarter_cols if 'SALE_total_spending' in col]\n",
    "\n",
    "\n",
    "\n",
    "target_col = '2024Q4_SALE_total_spending'\n",
    "\n",
    "\n",
    "if target_col not in df.columns:\n",
    "    raise ValueError(f\"Target column {target_col} not found in dataset\")\n",
    "\n",
    "\n",
    "def create_features(df, target_col):\n",
    "    \n",
    "    y = df[target_col].fillna(0)\n",
    "    \n",
    "    \n",
    "    feature_sets = {\n",
    "        \n",
    "        'seasonal': pd.get_dummies(pd.Series(['Q4']), prefix='quarter'),\n",
    "        \n",
    "        \n",
    "        'account': df[['age_days', 'activation_status_numeric', 'ebill_ind_numeric', \n",
    "                      'overlimit_type_flag_numeric', 'employee_code_numeric']],\n",
    "        \n",
    "        \n",
    "        'payment': df[['delinquency_count', 'zero_balance_count', 'overlimit_count',\n",
    "                      'payment_consistency_score', 'cycles_since_last_delinquency',\n",
    "                      'delinquency_trend', 'delinquency_acceleration']],\n",
    "        \n",
    "        \n",
    "        'financial': df[['utilization_rate', 'balance_to_credit_ratio', \n",
    "                        'cash_balance_to_cash_line_ratio', 'credit_grade_numeric',\n",
    "                        'financial_stress_indicator', 'weighted_utilization']],\n",
    "        \n",
    "        \n",
    "        'risk': df[['fraud_risk_score', 'high_delinquency_flag', \n",
    "                   'rapid_balance_change_flag', 'high_return_risk']],\n",
    "        \n",
    "        \n",
    "        'cash_flow': df[['cash_balance', 'cash_flow_efficiency', 'cash_balance_trend',\n",
    "                        'cash_to_debt_ratio', 'cash_buffer_ratio', \n",
    "                        'negative_cash_balance_flag', 'negative_cash_balance_frequency']],\n",
    "        \n",
    "        \n",
    "        'lifecycle': pd.get_dummies(df['customer_lifecycle_stage'], prefix='lifecycle'),\n",
    "        \n",
    "        \n",
    "        'sales_history': df[[f'sales_change_month_{i}_to_{i+1}' for i in range(1, 6)]],\n",
    "    }\n",
    "    \n",
    "    \n",
    "    lag_features = {}\n",
    "    \n",
    "    \n",
    "    all_quarters = sorted([col.split('_')[0] for col in spending_cols])\n",
    "    target_quarter = target_col.split('_')[0]\n",
    "    previous_quarters = [q for q in all_quarters if q < target_quarter]\n",
    "    \n",
    "    \n",
    "    for i, quarter in enumerate(previous_quarters[-4:], 1):\n",
    "        col = f\"{quarter}_SALE_total_spending\"\n",
    "        if col in df.columns:\n",
    "            lag_features[f'lag_{i}_quarter'] = df[col].fillna(0)\n",
    "    \n",
    "    feature_sets['lags'] = pd.DataFrame(lag_features)\n",
    "    \n",
    "    \n",
    "    growth_features = {}\n",
    "    for i in range(len(previous_quarters)-1):\n",
    "        q1 = previous_quarters[i]\n",
    "        q2 = previous_quarters[i+1]\n",
    "        col1 = f\"{q1}_SALE_total_spending\"\n",
    "        col2 = f\"{q2}_SALE_total_spending\"\n",
    "        if col1 in df.columns and col2 in df.columns:\n",
    "            \n",
    "            denominator = df[col1].replace(0, 0.001)\n",
    "            growth_features[f'growth_{q1}_to_{q2}'] = (df[col2] - df[col1]) / denominator\n",
    "    \n",
    "    feature_sets['growth'] = pd.DataFrame(growth_features)\n",
    "    \n",
    "    \n",
    "    rolling_features = {}\n",
    "    \n",
    "    \n",
    "    if len(previous_quarters) >= 2:\n",
    "        cols = [f\"{q}_SALE_total_spending\" for q in previous_quarters[-2:] if f\"{q}_SALE_total_spending\" in df.columns]\n",
    "        if cols:\n",
    "            rolling_features['last_2q_avg'] = df[cols].mean(axis=1)\n",
    "    \n",
    "    \n",
    "    if len(previous_quarters) >= 4:\n",
    "        cols = [f\"{q}_SALE_total_spending\" for q in previous_quarters[-4:] if f\"{q}_SALE_total_spending\" in df.columns]\n",
    "        if cols:\n",
    "            rolling_features['last_4q_avg'] = df[cols].mean(axis=1)\n",
    "            rolling_features['last_4q_std'] = df[cols].std(axis=1)\n",
    "    \n",
    "    \n",
    "    same_q_last_year = target_quarter.replace('2024', '2023')\n",
    "    same_q_col = f\"{same_q_last_year}_SALE_total_spending\"\n",
    "    if same_q_col in df.columns:\n",
    "        rolling_features['same_q_last_year'] = df[same_q_col].fillna(0)\n",
    "    \n",
    "    feature_sets['rolling'] = pd.DataFrame(rolling_features)\n",
    "    \n",
    "    \n",
    "    velocity_cols = [col for col in df.columns if 'velocity' in col and 'SALE' in col]\n",
    "    accel_cols = [col for col in df.columns if 'acceleration' in col and 'SALE' in col]\n",
    "    \n",
    "    feature_sets['velocity'] = df[velocity_cols] if velocity_cols else pd.DataFrame()\n",
    "    feature_sets['acceleration'] = df[accel_cols] if accel_cols else pd.DataFrame()\n",
    "    \n",
    "    \n",
    "    X = pd.concat([df[['current_account_nbr']], *feature_sets.values()], axis=1)\n",
    "    \n",
    "    \n",
    "    X = X.fillna(0)\n",
    "    \n",
    "    return X, y, feature_sets\n",
    "\n",
    "\n",
    "X, y, feature_sets = create_features(df, target_col)\n",
    "\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "numeric_cols = X.select_dtypes(include=['float64', 'int64']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "inf_mask = np.isinf(X[numeric_cols])\n",
    "if inf_mask.any().any():\n",
    "    print(f\"Found {inf_mask.sum().sum()} infinity values in the data\")\n",
    "    \n",
    "    \n",
    "    X[numeric_cols] = X[numeric_cols].replace([np.inf, -np.inf], np.nan)\n",
    "    \n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        if X[col].isna().any():\n",
    "            median_val = X[col].median()\n",
    "            X[col] = X[col].fillna(median_val)\n",
    "            print(f\"Replaced NaN values in {col} with median: {median_val}\")\n",
    "\n",
    "\n",
    "max_allowed = np.finfo('float64').max / 1e10  \n",
    "for col in numeric_cols:\n",
    "    too_large = np.abs(X[col]) > max_allowed\n",
    "    if too_large.any():\n",
    "        print(f\"Found {too_large.sum()} extremely large values in {col}\")\n",
    "        \n",
    "        X.loc[X[col] > max_allowed, col] = max_allowed\n",
    "        X.loc[X[col] < -max_allowed, col] = -max_allowed\n",
    "\n",
    "\n",
    "X[numeric_cols] = scaler.fit_transform(X[numeric_cols])\n",
    "\n",
    "\n",
    "def create_segments(df):\n",
    "    segments = {}\n",
    "    \n",
    "    \n",
    "    segments['new_accounts'] = pd.Series(df['age_days'] < 180, index=df.index)\n",
    "    segments['established_accounts'] = pd.Series((df['age_days'] >= 180) & (df['age_days'] < 730), index=df.index)\n",
    "    segments['mature_accounts'] = pd.Series(df['age_days'] >= 730, index=df.index)\n",
    "    \n",
    "    \n",
    "    if 'last_4q_std' in df.columns:\n",
    "        q75 = df['last_4q_std'].quantile(0.75)\n",
    "        segments['high_volatility'] = pd.Series(df['last_4q_std'] > q75, index=df.index)\n",
    "        segments['low_volatility'] = pd.Series(df['last_4q_std'] <= q75, index=df.index)\n",
    "    \n",
    "    \n",
    "    if 'utilization_rate' in df.columns:\n",
    "        segments['high_utilizers'] = pd.Series(df['utilization_rate'] > 70, index=df.index)\n",
    "        segments['low_utilizers'] = pd.Series(df['utilization_rate'] <= 30, index=df.index)\n",
    "        \n",
    "    return segments\n",
    "\n",
    "segments = create_segments(X)\n",
    "\n",
    "\n",
    "def train_base_model(X_train, y_train):\n",
    "    params = {\n",
    "        'objective': 'reg:squarederror',\n",
    "        'n_estimators': 200,\n",
    "        'max_depth': 6,\n",
    "        'learning_rate': 0.05,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'min_child_weight': 3,\n",
    "        'reg_alpha': 0.1,\n",
    "        'reg_lambda': 1.0,\n",
    "        'enable_categorical': True\n",
    "    }\n",
    "    \n",
    "    model = xgb.XGBRegressor(**params)\n",
    "    model.fit(X_train.drop('current_account_nbr', axis=1), y_train)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def train_segment_models(X, y, segments):\n",
    "    segment_models = {}\n",
    "    \n",
    "    for segment_name, segment_mask in segments.items():\n",
    "        if segment_mask.sum() > 100:  \n",
    "            X_segment = X[segment_mask]\n",
    "            y_segment = y[segment_mask]\n",
    "            \n",
    "            model = train_base_model(X_segment, y_segment)\n",
    "            segment_models[segment_name] = model\n",
    "    \n",
    "    return segment_models\n",
    "\n",
    "\n",
    "def apply_time_series_adjustment(account_id, history, prediction):\n",
    "    try:\n",
    "        \n",
    "        history = history.astype(float)\n",
    "        \n",
    "        \n",
    "        if len(history) >= 4:\n",
    "            \n",
    "            model = ARIMA(history, order=(1, 0, 0))\n",
    "            model_fit = model.fit()\n",
    "            \n",
    "            \n",
    "            forecast = model_fit.forecast(steps=1)[0]\n",
    "            \n",
    "            \n",
    "            \n",
    "            volatility = history.std() / history.mean() if history.mean() > 0 else 0\n",
    "            ml_weight = min(0.8, 0.5 + volatility)\n",
    "            ts_weight = 1 - ml_weight\n",
    "            \n",
    "            adjusted_prediction = ml_weight * prediction + ts_weight * forecast\n",
    "            \n",
    "            return adjusted_prediction\n",
    "        else:\n",
    "            return prediction\n",
    "    except:\n",
    "        \n",
    "        return prediction\n",
    "\n",
    "\n",
    "def predict_with_ensemble(X_test, base_model, segment_models, segments, historical_data):\n",
    "    \n",
    "    base_preds = base_model.predict(X_test.drop('current_account_nbr', axis=1))\n",
    "    \n",
    "    \n",
    "    final_preds = pd.Series(base_preds, index=X_test.index, name='predictions')\n",
    "    \n",
    "    \n",
    "    for segment_name, model in segment_models.items():\n",
    "        \n",
    "        segment_mask = segments[segment_name].loc[X_test.index]\n",
    "        \n",
    "        if segment_mask.sum() > 0:\n",
    "            \n",
    "            segment_data = X_test.loc[segment_mask]\n",
    "            segment_preds = model.predict(segment_data.drop('current_account_nbr', axis=1))\n",
    "            \n",
    "            \n",
    "            segment_preds_series = pd.Series(segment_preds, index=segment_data.index)\n",
    "            \n",
    "            \n",
    "            final_preds.loc[segment_mask] = 0.7 * segment_preds_series + 0.3 * base_preds[segment_mask]\n",
    "    \n",
    "    \n",
    "    return final_preds.values\n",
    "\n",
    "\n",
    "\n",
    "def create_historical_data(df, target_col):\n",
    "    \n",
    "    all_quarters = sorted([col.split('_')[0] for col in spending_cols])\n",
    "    target_quarter = target_col.split('_')[0]\n",
    "    previous_quarters = [q for q in all_quarters if q < target_quarter]\n",
    "    \n",
    "    \n",
    "    history_cols = [f\"{q}_SALE_total_spending\" for q in previous_quarters if f\"{q}_SALE_total_spending\" in df.columns]\n",
    "    historical_data = df[['current_account_nbr'] + history_cols].set_index('current_account_nbr')\n",
    "    \n",
    "    return historical_data\n",
    "\n",
    "historical_data = create_historical_data(df, target_col)\n",
    "\n",
    "\n",
    "cv_results = []\n",
    "X['quarter_Q4'] = X['quarter_Q4'].map({'0': 0, 'True': 1})\n",
    "for train_idx, test_idx in tscv.split(X):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    \n",
    "    \n",
    "    fold_segments = {}\n",
    "    for name, mask in segments.items():\n",
    "        fold_segments[name] = mask.loc[X_train.index]\n",
    "    \n",
    "    \n",
    "    segment_models = train_segment_models(X_train, y_train, fold_segments)\n",
    "    \n",
    "    \n",
    "    test_segments = {}\n",
    "    for name, mask in segments.items():\n",
    "        test_segments[name] = mask.loc[X_test.index]\n",
    "    \n",
    "    y_pred = predict_with_ensemble(X_test, base_model, segment_models, test_segments, historical_data)\n",
    "    \n",
    "    \n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    cv_results.append({\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'R2': r2\n",
    "    })\n",
    "\n",
    "\n",
    "cv_df = pd.DataFrame(cv_results)\n",
    "print(\"Cross-validation results:\")\n",
    "print(cv_df.mean())\n",
    "\n",
    "\n",
    "final_base_model = train_base_model(X, y)\n",
    "final_segment_models = train_segment_models(X, y, segments)\n",
    "\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.drop('current_account_nbr', axis=1).columns,\n",
    "    'Importance': final_base_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 20 important features:\")\n",
    "print(feature_importance.head(20))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importance.head(20))\n",
    "plt.title('Top 20 Features by Importance')\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_importance.png')\n",
    "\n",
    "\n",
    "def forecast_q4_spending(new_data):\n",
    "    \n",
    "    X_new, _, _ = create_features(new_data, target_col)\n",
    "    \n",
    "    \n",
    "    X_new[numeric_cols] = scaler.transform(X_new[numeric_cols])\n",
    "    \n",
    "    \n",
    "    new_segments = create_segments(X_new)\n",
    "    \n",
    "    \n",
    "    predictions = predict_with_ensemble(\n",
    "        X_new, \n",
    "        final_base_model, \n",
    "        final_segment_models, \n",
    "        new_segments, \n",
    "        historical_data\n",
    "    )\n",
    "    \n",
    "    \n",
    "    results = pd.DataFrame({\n",
    "        'current_account_nbr': new_data['current_account_nbr'],\n",
    "        'predicted_q4_spending': predictions\n",
    "    })\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "q4_forecast = forecast_q4_spending(df)\n",
    "print(\"\\nQ4 spending forecast summary:\")\n",
    "print(q4_forecast.describe())\n",
    "\n",
    "\n",
    "q4_forecast.to_csv('q4_spending_forecast.csv', index=False)\n",
    "\n",
    "print(\"\\nForecasting complete. Results saved to 'q4_spending_forecast.csv'\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
