{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "\n",
    "account_info_df = pd.read_csv('data/account_dim_20250325.csv')\n",
    "account_info_df['open_date'] = pd.to_datetime(account_info_df['open_date'], errors='coerce')\n",
    "\n",
    "transaction_df = pd.read_csv('data/transaction_fact_20250325.csv')\n",
    "statement_df = pd.read_csv('data/statement_fact_20250325.csv')\n",
    "fraud_case_df = pd.read_csv('data/fraud_claim_case_20250325.csv')\n",
    "fraud_transaction_df = pd.read_csv('data/fraud_claim_tran_20250325.csv')\n",
    "world_transaction_df = pd.read_csv('data/wrld_stor_tran_fact_20250325.csv')\n",
    "account_features_df = pd.read_csv('data/rams_batch_cur_20250325.csv')\n",
    "\n",
    "transaction_df['transaction_date'] = pd.to_datetime(transaction_df['transaction_date'])\n",
    "fraud_case_df['reported_date'] = pd.to_datetime(fraud_case_df['reported_date'])\n",
    "\n",
    "all_transactions = pd.concat([\n",
    "    transaction_df[['current_account_nbr', 'transaction_date', 'transaction_amt', 'transaction_type']],\n",
    "    world_transaction_df[['current_account_nbr', 'transaction_date', 'transaction_amt', 'transaction_type']]\n",
    "])\n",
    "\n",
    "\n",
    "transaction_pivot = all_transactions.pivot_table(\n",
    "    index='current_account_nbr', \n",
    "    columns=['transaction_date', 'transaction_type'], \n",
    "    values='transaction_amt', \n",
    "    aggfunc='sum'\n",
    ")\n",
    "\n",
    "\n",
    "transaction_pivot.columns = [f\"{date}_{type}\" for date, type in transaction_pivot.columns]\n",
    "\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "transaction_pivot_imputed = pd.DataFrame(\n",
    "    imputer.fit_transform(transaction_pivot),\n",
    "    index=transaction_pivot.index,\n",
    "    columns=transaction_pivot.columns\n",
    ")\n",
    "\n",
    "\n",
    "all_transactions_imputed = transaction_pivot_imputed.stack().reset_index()\n",
    "all_transactions_imputed[['transaction_date', 'transaction_type']] = all_transactions_imputed['level_1'].str.split('_', expand=True)\n",
    "\n",
    "all_transactions_imputed.columns = ['current_account_nbr', 'transaction_date', 'transaction_amt', 'transaction_type']\n",
    "all_transactions_imputed['quarter'] = pd.to_datetime(all_transactions_imputed['transaction_date'], format='ISO8601').dt.to_period('Q')\n",
    "all_transactions_imputed['month'] = pd.to_datetime(all_transactions_imputed['transaction_date'], format='ISO8601').dt.to_period('M')\n",
    "all_transactions_imputed['transaction_amt'] = all_transactions_imputed[0]\n",
    "all_transactions_imputed.drop(columns=['level_1', 0], inplace=True)\n",
    "all_transactions_imputed.to_csv(\"temp_all_trans.csv\")\n",
    "spending_behavior = all_transactions_imputed.groupby(['current_account_nbr', 'quarter', 'transaction_type'])['transaction_amt'].agg(\n",
    "    total_spending='sum',\n",
    "    avg_spending='mean',\n",
    "    std_spending='std'\n",
    ").reset_index()\n",
    "\n",
    "quarters = spending_behavior['quarter'].astype(str).unique()\n",
    "spending_pivot = pd.DataFrame(index=account_info_df['current_account_nbr'].unique())\n",
    "# Create a pivot table with all the metrics at once\n",
    "spending_pivot = spending_behavior.pivot_table(\n",
    "    index='current_account_nbr',\n",
    "    columns=['quarter', 'transaction_type'],\n",
    "    values=['total_spending', 'avg_spending', 'std_spending']\n",
    ")\n",
    "\n",
    "# Flatten the column names\n",
    "spending_pivot.columns = [f\"{quarter}_{transaction_type}_{metric}\" \n",
    "                         for (metric, quarter, transaction_type) in spending_pivot.columns]\n",
    "\n",
    "spending_pivot.reset_index(inplace=True)\n",
    "spending_pivot.rename(columns={'index': 'current_account_nbr'}, inplace=True)\n",
    "\n",
    "# First, identify the unique quarters and transaction types\n",
    "quarters = sorted(list(set([col.split('_')[0] for col in spending_pivot.columns if '_total_spending' in col])))\n",
    "transaction_types = sorted(list(set([col.split('_')[1] for col in spending_pivot.columns if '_total_spending' in col])))\n",
    "\n",
    "# Calculate velocity for each transaction type\n",
    "for i in range(len(quarters)-1):\n",
    "    q1 = quarters[i]\n",
    "    q2 = quarters[i+1]\n",
    "    \n",
    "    for trans_type in transaction_types:\n",
    "        q1_col = f'{q1}_{trans_type}_total_spending'\n",
    "        q2_col = f'{q2}_{trans_type}_total_spending'\n",
    "        \n",
    "        if q1_col in spending_pivot.columns and q2_col in spending_pivot.columns:\n",
    "            spending_pivot[f'{q1}_{q2}_{trans_type}_velocity'] = (\n",
    "                spending_pivot[q2_col] - spending_pivot[q1_col]\n",
    "            )\n",
    "        else:\n",
    "            print(f\"Skipping velocity calculation for {q1} to {q2} ({trans_type}) - columns not found\")\n",
    "    \n",
    "    # Calculate transaction frequency\n",
    "    q1_transactions = all_transactions_imputed[all_transactions_imputed['quarter'].astype(str) == q1]\n",
    "    q1_freq = q1_transactions.groupby('current_account_nbr').size()\n",
    "    spending_pivot[f'{q1}_transaction_frequency'] = q1_freq.reindex(spending_pivot.index).fillna(0)\n",
    "\n",
    "# Calculate acceleration for each transaction type\n",
    "for i in range(len(quarters)-2):\n",
    "    q1 = quarters[i]\n",
    "    q2 = quarters[i+1]\n",
    "    q3 = quarters[i+2]\n",
    "    \n",
    "    for trans_type in transaction_types:\n",
    "        v1_col = f'{q1}_{q2}_{trans_type}_velocity'\n",
    "        v2_col = f'{q2}_{q3}_{trans_type}_velocity'\n",
    "        \n",
    "        if v1_col in spending_pivot.columns and v2_col in spending_pivot.columns:\n",
    "            spending_pivot[f'{q1}_{q2}_{q3}_{trans_type}_acceleration'] = (\n",
    "                spending_pivot[v2_col] - spending_pivot[v1_col]\n",
    "            )\n",
    "        else:\n",
    "            print(f\"Skipping acceleration calculation for {q1} to {q3} ({trans_type}) - velocity columns not found\")\n",
    "\n",
    "# Optionally, calculate overall velocity and acceleration (across all transaction types)\n",
    "for i in range(len(quarters)-1):\n",
    "    q1 = quarters[i]\n",
    "    q2 = quarters[i+1]\n",
    "    \n",
    "    spending_pivot[f'{q1}_{q2}_overall_velocity'] = sum(\n",
    "        spending_pivot.get(f'{q1}_{q2}_{trans_type}_velocity', 0) \n",
    "        for trans_type in transaction_types\n",
    "    )\n",
    "\n",
    "for i in range(len(quarters)-2):\n",
    "    q1 = quarters[i]\n",
    "    q2 = quarters[i+1]\n",
    "    q3 = quarters[i+2]\n",
    "    \n",
    "    spending_pivot[f'{q1}_{q2}_{q3}_overall_acceleration'] = (\n",
    "        spending_pivot[f'{q2}_{q3}_overall_velocity'] - spending_pivot[f'{q1}_{q2}_overall_velocity']\n",
    "    )\n",
    "\n",
    "account_info_df['open_date'] = pd.to_datetime(account_info_df['open_date'], errors='coerce')\n",
    "account_info_df['open_date_naive'] = account_info_df['open_date'].dt.tz_localize(None)\n",
    "account_info_df['age_days'] = (datetime(2025, 3, 29) - account_info_df['open_date_naive']).dt.days\n",
    "\n",
    "activation_map = {'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9}\n",
    "account_info_df['activation_status_numeric'] = account_info_df['card_activation_flag'].map(activation_map)\n",
    "\n",
    "ebill_map = {'B': 1, 'E': 2, 'L': 3, ' ': 0, '': 0}\n",
    "account_info_df['ebill_ind_numeric'] = account_info_df['ebill_ind'].map(ebill_map)\n",
    "\n",
    "overlimit_map = {'0': 0, '1': 1, '2': 2, '3': 3}\n",
    "account_info_df['overlimit_type_flag_numeric'] = account_info_df['overlimit_type_flag'].map(overlimit_map)\n",
    "\n",
    "employee_map = {'0': 0, '1': 1, 'H': 2}\n",
    "account_info_df['employee_code_numeric'] = account_info_df['employee_code'].map(employee_map)\n",
    "\n",
    "finance_map = {'0': 0, '1': 1}\n",
    "account_info_df['special_finance_charge_numeric'] = account_info_df['special_finance_charge_ind'].map(finance_map)\n",
    "\n",
    "account_info_df['pscc_ind_numeric'] = account_info_df['pscc_ind'].astype(int)\n",
    "\n",
    "def analyze_payment_history(payment_hist):\n",
    "    if not isinstance(payment_hist, str):\n",
    "        return 0, 0, 0\n",
    "    \n",
    "    delinquency_count = sum(c in 'bcdefghjklmnopuvwx1234567' for c in payment_hist.lower())\n",
    "    zero_balance_count = payment_hist.lower().count('z')\n",
    "    overlimit_count = payment_hist.lower().count('o')\n",
    "    \n",
    "    return delinquency_count, zero_balance_count, overlimit_count\n",
    "\n",
    "payment_features = statement_df.apply(\n",
    "    lambda row: analyze_payment_history(row['payment_hist_1_12_mths']), \n",
    "    axis=1, \n",
    "    result_type='expand'\n",
    ")\n",
    "payment_features.columns = ['delinquency_count', 'zero_balance_count', 'overlimit_count']\n",
    "statement_df = pd.concat([statement_df, payment_features], axis=1)\n",
    "\n",
    "payment_summary = statement_df.groupby('current_account_nbr').agg(\n",
    "    delinquency_count=('delinquency_count', 'sum'),\n",
    "    zero_balance_count=('zero_balance_count', 'sum'),\n",
    "    overlimit_count=('overlimit_count', 'sum'),\n",
    "    return_check_count_total=('return_check_cnt_total', 'max')\n",
    ").reset_index()\n",
    "\n",
    "\n",
    "fraud_case_summary = fraud_case_df.groupby('current_account_nbr').agg(\n",
    "    gross_fraud_amt=('gross_fraud_amt', 'sum'),\n",
    "    net_fraud_amt=('net_fraud_amt', 'sum'),\n",
    "    fraud_frequency=('case_id', 'count')\n",
    ").reset_index()\n",
    "\n",
    "fraud_case_summary['fraud_ratio'] = fraud_case_summary['net_fraud_amt'] / fraud_case_summary['gross_fraud_amt']\n",
    "fraud_codes = {13, 22, 23, 46, 48, 62, 80}\n",
    "\n",
    "if 'external_status_reason_code' in account_info_df.columns:\n",
    "    account_info_df['external_status_numeric'] = account_info_df['external_status_reason_code'].apply(lambda x: 1 if x in fraud_codes else 0)\n",
    "\n",
    "account_features_df = account_features_df.rename(columns={\n",
    "    'cu_account_nbr': 'current_account_nbr',\n",
    "    'ca_current_utilz': 'utilization_rate',\n",
    "    'cu_otb': 'open_to_buy',\n",
    "    'cu_cur_balance': 'current_balance'\n",
    "})\n",
    "\n",
    "latest_transaction = all_transactions_imputed.groupby('current_account_nbr')['transaction_date'].max().reset_index()\n",
    "latest_transaction.columns = ['current_account_nbr', 'last_transaction_date']\n",
    "latest_transaction['days_since_last_transaction'] = (\n",
    "    datetime(2025, 3, 29) - pd.to_datetime(latest_transaction['last_transaction_date'])\n",
    ").dt.days\n",
    "\n",
    "account_features_df['max_days_delinquent'] = account_features_df['cu_nbr_days_dlq']\n",
    "account_features_df['current_cycles_delinquent'] = account_features_df['cu_cur_nbr_due']\n",
    "\n",
    "account_features_df['balance_to_credit_ratio'] = account_features_df['current_balance'] / account_features_df['cu_crd_line']\n",
    "account_features_df['cash_balance_to_cash_line_ratio'] = account_features_df['ca_cash_bal_pct_cash_line'] / 100\n",
    "\n",
    "credit_grade_map = {'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5}\n",
    "account_features_df['credit_grade_numeric'] = account_features_df['rb_crd_gr_new_crd_gr'].map(credit_grade_map)\n",
    "\n",
    "account_features_df['months_since_active'] = account_features_df['ca_mnths_since_active']\n",
    "account_features_df['months_since_credit_limit_change'] = account_features_df['ca_mnths_since_cl_chng']\n",
    "account_features_df['months_on_books'] = account_features_df['ca_mob']\n",
    "\n",
    "account_features_df['utilization_stability'] = account_features_df['ca_avg_utilz_lst_3_mnths'] / account_features_df['ca_avg_utilz_lst_6_mnths']\n",
    "account_features_df['financial_stress_indicator'] = account_features_df['open_to_buy'] / account_features_df['cu_crd_line']\n",
    "\n",
    "monthly_sales_columns = [f'mo_tot_sales_array_{i}' for i in range(1, 7)]\n",
    "account_features_df['total_sales_last_6_months'] = account_features_df[monthly_sales_columns].sum(axis=1)\n",
    "account_features_df['avg_monthly_sales_last_6_months'] = account_features_df[monthly_sales_columns].mean(axis=1)\n",
    "\n",
    "account_features_df['sales_trend'] = (account_features_df['mo_tot_sales_array_1'] - \n",
    "                                      account_features_df['mo_tot_sales_array_6']) / 6\n",
    "\n",
    "account_features_df['nsf_count_last_12_months'] = account_features_df['ca_nsf_count_lst_12_months']\n",
    "\n",
    "account_features_df['behavior_score_change'] = account_features_df['rb_new_bhv_scr'] - account_features_df['cu_bhv_scr']\n",
    "account_features_df['behavior_score_percent_change'] = (account_features_df['behavior_score_change'] / \n",
    "                                                       account_features_df['cu_bhv_scr']) * 100\n",
    "\n",
    "account_features_df['high_delinquency_flag'] = (account_features_df['cu_nbr_days_dlq'] > 60).astype(int)\n",
    "account_features_df['rapid_balance_change_flag'] = (\n",
    "    (account_features_df['ca_avg_utilz_lst_3_mnths'] - account_features_df['ca_avg_utilz_lst_6_mnths']) > 20\n",
    ").astype(int)\n",
    "\n",
    "account_features_df['fraud_risk_score'] = (\n",
    "    account_features_df['high_delinquency_flag'] * 3 + \n",
    "    account_features_df['rapid_balance_change_flag'] * 2 +\n",
    "    (account_features_df['months_since_active'] < 3).astype(int) * 2 +\n",
    "    (account_features_df['behavior_score_percent_change'] < -10).astype(int) * 3 +\n",
    "    account_features_df['credit_grade_numeric'] * 5\n",
    "    \n",
    ")\n",
    "\n",
    "for i in range(1, 6):\n",
    "    account_features_df[f'sales_change_month_{i}_to_{i+1}'] = (\n",
    "        account_features_df[f'mo_tot_sales_array_{i}'] - account_features_df[f'mo_tot_sales_array_{i+1}']\n",
    "    )\n",
    "\n",
    "account_features_df['sales_volatility'] = account_features_df[monthly_sales_columns].std(axis=1)\n",
    "\n",
    "\n",
    "\n",
    "total_spending = all_transactions_imputed.groupby('current_account_nbr')['transaction_amt'].sum().reset_index()\n",
    "account_features_df = account_features_df.merge(total_spending, on='current_account_nbr', how='left')\n",
    "account_features_df['transaction_amt'] = account_features_df['transaction_amt'].fillna(0)\n",
    "account_features_df['cash_balance'] = account_features_df['cu_crd_line'] - account_features_df['transaction_amt']\n",
    "\n",
    "\n",
    "\n",
    "account_features_df['negative_cash_balance_flag'] = (account_features_df['cash_balance'] < 0).astype(int)\n",
    "\n",
    "monthly_cash_balances = all_transactions_imputed.groupby(['current_account_nbr', 'month'])['transaction_amt'].sum().reset_index()\n",
    "\n",
    "\n",
    "monthly_cash_balances = monthly_cash_balances.sort_values(['current_account_nbr', 'month'])\n",
    "monthly_cash_balances['running_cash_balance'] = monthly_cash_balances.groupby('current_account_nbr')['transaction_amt'].cumsum()\n",
    "\n",
    "\n",
    "cash_volatility = monthly_cash_balances.groupby('current_account_nbr')['running_cash_balance'].std().reset_index()\n",
    "cash_volatility.columns = ['current_account_nbr', 'cash_balance_volatility']\n",
    "account_features_df = account_features_df.merge(cash_volatility, on='current_account_nbr', how='left')\n",
    "account_features_df['cash_balance_volatility'] = account_features_df['cash_balance_volatility'].fillna(0)\n",
    "\n",
    "\n",
    "account_features_df['cash_flow_efficiency'] = account_features_df['cash_balance'] / account_features_df['cu_crd_line']\n",
    "account_features_df['cash_flow_efficiency'] = account_features_df['cash_flow_efficiency'].clip(lower=-1, upper=1)\n",
    "\n",
    "\n",
    "\n",
    "monthly_trends = monthly_cash_balances.groupby('current_account_nbr').apply(\n",
    "    lambda x: np.polyfit(range(len(x)), x['running_cash_balance'], 1)[0] if len(x) > 1 else 0\n",
    ").reset_index()\n",
    "monthly_trends.columns = ['current_account_nbr', 'cash_balance_trend']\n",
    "account_features_df = account_features_df.merge(monthly_trends, on='current_account_nbr', how='left')\n",
    "account_features_df['cash_balance_trend'] = account_features_df['cash_balance_trend'].fillna(0)\n",
    "\n",
    "\n",
    "account_features_df['cash_to_debt_ratio'] = account_features_df['cash_balance'] / account_features_df['current_balance']\n",
    "account_features_df['cash_to_debt_ratio'] = account_features_df['cash_to_debt_ratio'].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "\n",
    "account_features_df['cash_buffer_ratio'] = account_features_df['cash_balance'] / account_features_df['avg_monthly_sales_last_6_months']\n",
    "account_features_df['cash_buffer_ratio'] = account_features_df['cash_buffer_ratio'].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "\n",
    "negative_accounts = monthly_cash_balances[monthly_cash_balances['running_cash_balance'] < 0]\n",
    "negative_frequency = negative_accounts.groupby('current_account_nbr').size().reset_index()\n",
    "negative_frequency.columns = ['current_account_nbr', 'negative_cash_balance_frequency']\n",
    "\n",
    "negative_magnitude = negative_accounts.groupby('current_account_nbr')['running_cash_balance'].mean().reset_index()\n",
    "negative_magnitude.columns = ['current_account_nbr', 'average_negative_cash_balance']\n",
    "\n",
    "account_features_df = account_features_df.merge(negative_frequency, on='current_account_nbr', how='left')\n",
    "account_features_df = account_features_df.merge(negative_magnitude, on='current_account_nbr', how='left')\n",
    "account_features_df['negative_cash_balance_frequency'] = account_features_df['negative_cash_balance_frequency'].fillna(0)\n",
    "account_features_df['average_negative_cash_balance'] = account_features_df['average_negative_cash_balance'].fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "monthly_cash_balances['is_negative'] = monthly_cash_balances['running_cash_balance'] < 0\n",
    "monthly_cash_balances['group'] = (monthly_cash_balances['is_negative'] != \n",
    "                                 monthly_cash_balances['is_negative'].shift()).cumsum()\n",
    "\n",
    "\n",
    "negative_streaks = monthly_cash_balances[monthly_cash_balances['is_negative']].groupby(\n",
    "    ['current_account_nbr', 'group']).size().reset_index()\n",
    "negative_streaks.columns = ['current_account_nbr', 'group', 'streak_duration']\n",
    "\n",
    "\n",
    "max_negative_duration = negative_streaks.groupby('current_account_nbr')['streak_duration'].max().reset_index()\n",
    "max_negative_duration.columns = ['current_account_nbr', 'max_negative_cash_balance_duration']\n",
    "\n",
    "account_features_df = account_features_df.merge(max_negative_duration, on='current_account_nbr', how='left')\n",
    "account_features_df['max_negative_cash_balance_duration'] = account_features_df['max_negative_cash_balance_duration'].fillna(0)\n",
    "\n",
    "\n",
    "account_features_df.drop(columns=['transaction_amt'], inplace=True)\n",
    "\n",
    "account_features_df['cash_balance_pct_credit_line'] = (account_features_df['cash_balance'] / account_features_df['cu_crd_line']) * 100\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "account_features_df['customer_lifecycle_stage'] = pd.cut(\n",
    "    account_features_df['months_on_books'], \n",
    "    bins=[0, 3, 12, float('inf')],\n",
    "    labels=['New', 'Established', 'Mature']\n",
    ")\n",
    "\n",
    "\n",
    "account_features_df['customer_lifetime_value'] = (\n",
    "    account_features_df['total_sales_last_6_months'] * \n",
    "    (1 + account_features_df['months_on_books'] / 12)\n",
    ")\n",
    "\n",
    "\n",
    "def analyze_payment_trend(payment_hist):\n",
    "    if not isinstance(payment_hist, str) or len(payment_hist) < 3:\n",
    "        return 0, 0, 0, 0\n",
    "    \n",
    "    delinq_map = {\n",
    "        'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4, 'f': 5, 'g': 6, 'h': 7,\n",
    "        'i': 0, 'j': 1, 'k': 2, 'l': 3, 'm': 4, 'n': 5, 'o': 6, 'p': 7,\n",
    "        'u': 4, 'v': 5, 'w': 6, 'x': 7,\n",
    "        '0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7,\n",
    "        'z': 0, '%': 0, '#': 0, '+': 0, '-': 0, 'q': 0\n",
    "    }\n",
    "    \n",
    "    \n",
    "    first_3_months = payment_hist[:3].lower()\n",
    "    last_3_months = payment_hist[-3:].lower()\n",
    "    \n",
    "    first_3_delinq = [delinq_map.get(c, 0) for c in first_3_months]\n",
    "    last_3_delinq = [delinq_map.get(c, 0) for c in last_3_months]\n",
    "    \n",
    "    \n",
    "    first_3_avg = sum(first_3_delinq) / len(first_3_delinq) if first_3_delinq else 0\n",
    "    last_3_avg = sum(last_3_delinq) / len(last_3_delinq) if last_3_delinq else 0\n",
    "    \n",
    "    \n",
    "    delinquency_trend = last_3_avg - first_3_avg\n",
    "    \n",
    "    \n",
    "    on_time_count = sum(1 for c in payment_hist.lower() if c in 'aiz%#+q-')\n",
    "    payment_consistency = on_time_count / len(payment_hist)\n",
    "    \n",
    "    \n",
    "    cycles_since_last_delinq = 0\n",
    "    for i, c in enumerate(reversed(payment_hist.lower())):\n",
    "        if c in 'bcdefghjklmnopuvwx1234567':\n",
    "            cycles_since_last_delinq = i\n",
    "            break\n",
    "    \n",
    "    \n",
    "    delinq_values = [delinq_map.get(c, 0) for c in payment_hist.lower()]\n",
    "    delinq_diff = [delinq_values[i] - delinq_values[i+1] for i in range(len(delinq_values)-1)]\n",
    "    delinq_acceleration = sum(delinq_diff) / len(delinq_diff) if delinq_diff else 0\n",
    "    \n",
    "    return delinquency_trend, payment_consistency, cycles_since_last_delinq, delinq_acceleration\n",
    "\n",
    "\n",
    "payment_trend_features = statement_df.apply(\n",
    "    lambda row: analyze_payment_trend(row['payment_hist_1_12_mths']), \n",
    "    axis=1, \n",
    "    result_type='expand'\n",
    ")\n",
    "payment_trend_features.columns = [\n",
    "    'delinquency_trend', \n",
    "    'payment_consistency_score', \n",
    "    'cycles_since_last_delinquency',\n",
    "    'delinquency_acceleration'\n",
    "]\n",
    "statement_df = pd.concat([statement_df, payment_trend_features], axis=1)\n",
    "\n",
    "\n",
    "payment_trend_summary = statement_df.groupby('current_account_nbr').agg(\n",
    "    delinquency_trend=('delinquency_trend', 'mean'),\n",
    "    payment_consistency_score=('payment_consistency_score', 'mean'),\n",
    "    cycles_since_last_delinquency=('cycles_since_last_delinquency', 'min'),\n",
    "    delinquency_acceleration=('delinquency_acceleration', 'mean'),\n",
    "    \n",
    ").reset_index()\n",
    "\n",
    "\n",
    "account_features_df['spending_to_balance_ratio'] = (\n",
    "    account_features_df['total_sales_last_6_months'] / \n",
    "    account_features_df['current_balance']\n",
    ").replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "\n",
    "account_features_df['external_credit_score'] = account_features_df['cu_crd_bureau_scr']\n",
    "\n",
    "\n",
    "payment_summary['high_return_risk'] = (payment_summary['return_check_count_total'] > 3).astype(int)\n",
    "\n",
    "\n",
    "account_features_df['weighted_utilization'] = (\n",
    "    0.5 * account_features_df['utilization_rate'] + \n",
    "    0.3 * account_features_df['ca_avg_utilz_lst_3_mnths'] + \n",
    "    0.2 * account_features_df['ca_avg_utilz_lst_6_mnths']\n",
    ")\n",
    "\n",
    "\n",
    "account_features_df['credit_limit_utilization_trend'] = np.where(\n",
    "    account_features_df['months_since_credit_limit_change'] > 0,\n",
    "    (account_features_df['utilization_rate'] - account_features_df['ca_avg_utilz_lst_6_mnths']) / \n",
    "    account_features_df['months_since_credit_limit_change'],\n",
    "    0\n",
    ")\n",
    "\n",
    "\n",
    "account_features_df['income_stability_score'] = 1 / (1 + account_features_df['sales_volatility'])\n",
    "account_features_df['income_stability_score'] = account_features_df['income_stability_score'].fillna(0)\n",
    "\n",
    "\n",
    "account_features_df['cash_buffer_ratio'] = account_features_df['cash_balance'] / account_features_df['avg_monthly_sales_last_6_months']\n",
    "account_features_df['cash_buffer_ratio'] = account_features_df['cash_buffer_ratio'].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "\n",
    "final_data = account_info_df.copy()\n",
    "final_data = final_data.merge(spending_pivot, on='current_account_nbr', how='left')\n",
    "final_data = final_data.merge(payment_summary, on='current_account_nbr', how='left')\n",
    "final_data = final_data.merge(payment_trend_summary, on='current_account_nbr', how='left')\n",
    "final_data = final_data.merge(fraud_case_summary, left_on='current_account_nbr', right_on='current_account_nbr', how='left')\n",
    "final_data = final_data.merge(latest_transaction[['current_account_nbr', 'days_since_last_transaction']], on='current_account_nbr', how='left')\n",
    "\n",
    "final_data ['payment_full_consistency_score'] = (\n",
    "    final_data ['payment_consistency_score'] * \n",
    "    (1 + final_data ['zero_balance_count'] / 12)\n",
    ")\n",
    "\n",
    "account_features_columns = [\n",
    "    'current_account_nbr', 'utilization_rate', 'open_to_buy', 'current_balance',\n",
    "    'max_days_delinquent', 'current_cycles_delinquent', 'balance_to_credit_ratio',\n",
    "    'cash_balance_to_cash_line_ratio', 'credit_grade_numeric', 'months_since_active',\n",
    "    'months_since_credit_limit_change', 'utilization_stability', 'financial_stress_indicator',\n",
    "    'months_on_books', 'total_sales_last_6_months', 'avg_monthly_sales_last_6_months',\n",
    "    'sales_trend', 'nsf_count_last_12_months', 'behavior_score_change',\n",
    "    'behavior_score_percent_change', 'high_delinquency_flag', 'rapid_balance_change_flag',\n",
    "    'fraud_risk_score', 'sales_volatility', 'customer_lifecycle_stage', 'customer_lifetime_value',\n",
    "    'spending_to_balance_ratio', 'external_credit_score', 'weighted_utilization',\n",
    "    'credit_limit_utilization_trend', 'income_stability_score', 'cash_balance',\n",
    "    'cash_balance_pct_credit_line', 'cash_buffer_ratio'\n",
    "]\n",
    "\n",
    "account_features_columns.extend([\n",
    "    'negative_cash_balance_flag',\n",
    "    'cash_balance_volatility',\n",
    "    'cash_flow_efficiency',\n",
    "    'cash_balance_trend',\n",
    "    'cash_to_debt_ratio',\n",
    "    'cash_buffer_ratio',\n",
    "    'negative_cash_balance_frequency',\n",
    "    'average_negative_cash_balance',\n",
    "    'max_negative_cash_balance_duration'\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "for i in range(1, 6):\n",
    "    account_features_columns.append(f'sales_change_month_{i}_to_{i+1}')\n",
    "\n",
    "final_data = final_data.merge(\n",
    "    account_features_df[account_features_columns], \n",
    "    on='current_account_nbr', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "\n",
    "final_data.fillna({\n",
    "    'gross_fraud_amt': 0,\n",
    "    'net_fraud_amt': 0,\n",
    "    'fraud_frequency': 0,\n",
    "    'fraud_ratio': 0,\n",
    "    'delinquency_count': 0,\n",
    "    'zero_balance_count': 0,\n",
    "    'overlimit_count': 0,\n",
    "    'return_check_count_total': 0,\n",
    "    'max_days_delinquent': 0,\n",
    "    'current_cycles_delinquent': 0,\n",
    "    'nsf_count_last_12_months': 0,\n",
    "    'fraud_risk_score': 0,\n",
    "    'delinquency_trend': 0,\n",
    "    'payment_consistency_score': 0,\n",
    "    'cycles_since_last_delinquency': 12,  \n",
    "    'delinquency_acceleration': 0,\n",
    "    'high_return_risk': 0,\n",
    "    'weighted_utilization': 0,\n",
    "    'credit_limit_utilization_trend': 0,\n",
    "    'income_stability_score': 0,\n",
    "    'payment_full_consistency_score': 0,\n",
    "    'cash_balance': 0,\n",
    "    'cash_balance_pct_credit_line': 0,\n",
    "    'cash_buffer_ratio': 0\n",
    "}, inplace=True)\n",
    "\n",
    "final_data.fillna({\n",
    "    'negative_cash_balance_flag': 0,\n",
    "    'cash_balance_volatility': 0,\n",
    "    'cash_flow_efficiency': 0,\n",
    "    'cash_balance_trend': 0,\n",
    "    'cash_to_debt_ratio': 0,\n",
    "    'cash_buffer_ratio': 0,\n",
    "    'negative_cash_balance_frequency': 0,\n",
    "    'average_negative_cash_balance': 0,\n",
    "    'max_negative_cash_balance_duration': 0\n",
    "}, inplace=True)\n",
    "\n",
    "threshold = int(0.2 * final_data.shape[1])  \n",
    "final_data.dropna(thresh=threshold, inplace=True)\n",
    "\n",
    "\n",
    "final_data.to_csv(\"enriched_account_information.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def perform_eda(df, file_name):\n",
    "    print(f\"Performing EDA for {file_name}...\")\n",
    "    \n",
    "    \n",
    "    empty_columns = [col for col in df.columns if df[col].isnull().all() or (df[col].astype(str).str.strip() == '').all()]\n",
    "    if empty_columns:\n",
    "        print(f\"Dropping columns with all empty values: {empty_columns}\")\n",
    "        df = df.drop(columns=empty_columns)\n",
    "    \n",
    "    \n",
    "    constant_columns = [col for col in df.columns if df[col].nunique() == 1]\n",
    "    if constant_columns:\n",
    "        print(f\"Dropping columns with all identical values: {constant_columns}\")\n",
    "        df = df.drop(columns=constant_columns)\n",
    "    \n",
    "    print(\"Shape of the data after dropping empty and constant-value columns:\", df.shape)\n",
    "    print(\"Columns:\", df.columns)\n",
    "    print(\"Data Types:\\n\", df.dtypes)\n",
    "    \n",
    "    \n",
    "    missing_values = df.isnull().sum()\n",
    "    print(\"Missing Values:\\n\", missing_values[missing_values > 0])\n",
    "    \n",
    "    \n",
    "    numerical_features = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    categorical_features = df.select_dtypes(include=['object']).columns.tolist()\n",
    "    \n",
    "    \n",
    "    date_features = []\n",
    "    for col in categorical_features:\n",
    "        try:\n",
    "            pd.to_datetime(df[col], errors='raise')  \n",
    "            date_features.append(col)\n",
    "        except Exception:\n",
    "            pass  \n",
    "    \n",
    "    \n",
    "    if numerical_features:\n",
    "        print(\"\\nNumerical Feature Analysis:\")\n",
    "        print(df[numerical_features].describe())\n",
    "        \n",
    "        \n",
    "        corr_matrix = df[numerical_features].corr()\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "        plt.title(f\"Correlation Matrix for {file_name}\")\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "        for col in numerical_features:\n",
    "            print(f\"\\nStatistics for {col}:\")\n",
    "            print(f\"Mean: {df[col].mean():.2f}, Median: {df[col].median():.2f}, Min: {df[col].min()}, Max: {df[col].max()}, Std: {df[col].std():.2f}\")\n",
    "            \n",
    "            \n",
    "            plt.figure(figsize=(10, 5))\n",
    "            sns.histplot(df[col], kde=True)\n",
    "            plt.title(f\"Distribution of {col}\")\n",
    "            plt.show()\n",
    "            \n",
    "            sns.boxplot(x=df[col])\n",
    "            plt.title(f\"Boxplot of {col}\")\n",
    "            plt.show()\n",
    "    \n",
    "    \n",
    "    if categorical_features:\n",
    "        print(\"\\nSkipping Categorical Feature Analysis.\")\n",
    "    \n",
    "    \n",
    "    if date_features:\n",
    "        print(\"\\nDate Feature Analysis:\")\n",
    "        for col in date_features:\n",
    "            try:\n",
    "                \n",
    "                df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "                \n",
    "                \n",
    "                valid_dates = df[col].dropna()\n",
    "                invalid_count = df[col].isna().sum()\n",
    "                \n",
    "                if invalid_count > 0:\n",
    "                    print(f\"Found {invalid_count} invalid dates in {col}\")\n",
    "                    \n",
    "                if not valid_dates.empty:\n",
    "                    print(f\"\\nDate Range for {col}:\")\n",
    "                    print(f\"Min Date: {valid_dates.min()}, Max Date: {valid_dates.max()}\")\n",
    "                    \n",
    "                    \n",
    "                    if valid_dates.dt.tz is not None:\n",
    "                        valid_dates = valid_dates.dt.tz_localize(None)\n",
    "                    \n",
    "                    \n",
    "                    date_range = valid_dates.dt.to_period('M').value_counts().sort_index()\n",
    "                    \n",
    "                    \n",
    "                    plt.figure(figsize=(12, 6))\n",
    "                    date_range.plot(kind='bar')\n",
    "                    plt.title(f\"Monthly Trend Analysis of {col}\")\n",
    "                    plt.xlabel(\"Month\")\n",
    "                    plt.ylabel(\"Frequency\")\n",
    "                    plt.xticks(rotation=45)\n",
    "                    plt.show()\n",
    "                else:\n",
    "                    print(f\"No valid dates found in column {col}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing date column {col}: {e}\")\n",
    "\n",
    "def process_all_csvs(folder_path):\n",
    "    files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "    \n",
    "    for file in files:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            perform_eda(df, file)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file}: {e}\")\n",
    "\n",
    "\n",
    "data_folder = \"data\"\n",
    "process_all_csvs(data_folder)\n",
    "\n",
    "\n",
    "def process_all_csvs(folder_path):\n",
    "    files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "    \n",
    "    for file in files:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            perform_eda(df, file)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file}: {e}\")\n",
    "\n",
    "\n",
    "data_folder = \"data\"\n",
    "process_all_csvs(data_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
